{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d04db7-d683-4a88-b370-c53f819af549",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9335b7e-b25f-4c2e-a48d-c3de023462b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protein_datasets(dataset_pathes, fields_column='protein'):\n",
    "\n",
    "    datasets = dict()\n",
    "\n",
    "    for dataset_name, dataset_pathes in dataset_pathes.items():\n",
    "\n",
    "        dataset = ProteinsDataset(fields_column=fields_column)\n",
    "\n",
    "        for dataset_path in dataset_pathes:\n",
    "\n",
    "            dataset.extend(dataset_path)\n",
    "\n",
    "        datasets[dataset_name] = dataset\n",
    "        \n",
    "    print(\"Datasets loaded:\", *datasets.keys())\n",
    "        \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4994109-9ecd-4e00-8a04-8ac2f825a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_regressors(regressors_path):\n",
    "\n",
    "    with open(regressors_path, 'rb') as handle:\n",
    "        regressors = pickle.load(handle)\n",
    "    \n",
    "    print(\"Regressors loaded:\", *regressors.keys())\n",
    "    \n",
    "    return regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45152d-e0ca-407f-9a3c-6803bbf02a35",
   "metadata": {},
   "source": [
    "### Decode and Enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864f832-e074-4882-b344-50b835bc5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sampling_results(qubo, dataset, sampling_results):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for sampling_result in sampling_results.data():\n",
    "\n",
    "        samples = np.array(list(sampling_result.sample.values()))\n",
    "        \n",
    "        bits = qubo.one_hot_to_bits(samples)\n",
    "        \n",
    "        symbols = dataset.decode(bits)\n",
    "        \n",
    "        # decimal = sum(number * 2 ** position for position, number in enumerate(reversed(bits)))\n",
    "\n",
    "        reversed_indices = np.arange(len(bits))[::-1]\n",
    "\n",
    "        powers_of_two = 1 << reversed_indices\n",
    "        \n",
    "        decimal = bits.dot(powers_of_two)\n",
    "\n",
    "        result = {'decimal': decimal,\n",
    "                  'samples': samples,\n",
    "                  'bits': bits,\n",
    "                  'symbols': symbols,\n",
    "                  'qubo_energy': sampling_result.energy,\n",
    "                  'num_occurrences': sampling_result.num_occurrences}\n",
    "        \n",
    "#         if 'X' in symbols:\n",
    "            \n",
    "#             # print(result)\n",
    "            \n",
    "#             continue\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf161ec-5abb-4eec-a34e-25d89f3b6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_cold_decode_sampling_results(qubo, dataset, sampling_results):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for sampling_result in sampling_results.data():\n",
    "\n",
    "        samples = np.array(list(sampling_result.sample.values()))\n",
    "        \n",
    "        # bits = qubo.one_hot_to_bits(samples)\n",
    "        \n",
    "        bits = samples\n",
    "        \n",
    "        symbols = dataset.decode(bits)\n",
    "        \n",
    "        # decimal = sum(number * 2 ** position for position, number in enumerate(reversed(bits)))\n",
    "\n",
    "        reversed_indices = np.arange(len(bits))[::-1]\n",
    "\n",
    "        powers_of_two = 1 << reversed_indices\n",
    "        \n",
    "        decimal = bits.dot(powers_of_two)\n",
    "\n",
    "        result = {'decimal': decimal,\n",
    "                  'samples': samples,\n",
    "                  'bits': bits,\n",
    "                  'symbols': symbols,\n",
    "                  'qubo_energy': sampling_result.energy,\n",
    "                  'num_occurrences': sampling_result.num_occurrences}\n",
    "        \n",
    "        # print(symbols)\n",
    "        \n",
    "        # if 'X' in symbols:\n",
    "            \n",
    "            # print(result)\n",
    "            \n",
    "            # continue\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bec19a-224a-45fb-9090-c22276ca6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_energies(results):\n",
    "    \n",
    "    bits = np.vstack(results['bits'])\n",
    "    \n",
    "    target_binding_energies = target_regressor.predict(bits)\n",
    "    \n",
    "    offtarget_binding_energies = [offtarget_regressor.predict(bits) \n",
    "                                  for offtarget_regressor in offtarget_regressors]\n",
    "    \n",
    "    results['target_binding_energy'] = target_binding_energies\n",
    "    results['offtarget_binding_energy'] = np.vstack(offtarget_binding_energies).sum(axis=0)\n",
    "    results['offtarget_binding_energy'] = results['offtarget_binding_energy'] / len(offtarget_proteins)\n",
    "    \n",
    "    \n",
    "    X_PENALTY = 0.5\n",
    "\n",
    "    x_penalties = results['symbols'].str.count('X') * X_PENALTY\n",
    "\n",
    "    results['target_binding_energy'] += x_penalties\n",
    "    \n",
    "    print(\"x_penalties:\", x_penalties.to_numpy(), x_penalties.mean())    \n",
    "    \n",
    "    \n",
    "    \n",
    "    results['binding_energy'] = results['target_binding_energy'] - results['offtarget_binding_energy']\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf5fa1-b470-43ef-898b-a155e860bd0d",
   "metadata": {},
   "source": [
    "### Proteins Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a3ef2-6359-4efd-994a-79edcc7ebec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinsDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    # Encoding\n",
    "\n",
    "    AMINOACIDS = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "    default_dna_encoding = {'A': (0, 0), 'C': (0, 1), 'G': (1, 0), 'T': (1, 1)}\n",
    "\n",
    "    default_amino_encoding = {aminoacid: tuple(int(bit) for bit in f\"{index:05b}\")\n",
    "                              for index, aminoacid in enumerate(AMINOACIDS)}\n",
    "    \n",
    "    default_encodings = {'seq': default_dna_encoding,\n",
    "                         'protein': default_amino_encoding}\n",
    "    \n",
    "    \n",
    "    def __init__(self, fields_column, target_column='energy', encoding=None):\n",
    "        \n",
    "        self.fields_column = fields_column\n",
    "        self.target_column = target_column\n",
    "        \n",
    "        self.encoding = encoding or self.default_encodings[fields_column]\n",
    "            \n",
    "        self.decoding = {bits: symbol for symbol, bits in self.encoding.items()}\n",
    "\n",
    "        self.bits_per_symbol = len(list(self.encoding.values())[0])\n",
    "               \n",
    "        self.fields = None\n",
    "        self.targets = np.array([])        \n",
    "        self.data = pd.DataFrame()\n",
    "        \n",
    "    \n",
    "    def extend(self, dataset_path):        \n",
    "        \n",
    "        data = pd.read_csv(dataset_path, index_col=0)\n",
    "        \n",
    "        column_mapping = self.unify_column_names(data.columns)\n",
    "        \n",
    "        data.rename(columns=column_mapping, inplace=True)\n",
    "        \n",
    "        \n",
    "        # Fields\n",
    "        \n",
    "        field_series = data[self.fields_column]\n",
    "        \n",
    "        field_bits_count = len(field_series[0]) * self.bits_per_symbol\n",
    "        \n",
    "        if self.fields is None:            \n",
    "            self.fields = np.array([]).reshape(0, field_bits_count).astype(int)\n",
    "        \n",
    "        new_fields = np.vstack(field_series.apply(self.encode))\n",
    "        new_targets = data[self.target_column].to_numpy()\n",
    "        \n",
    "        self.fields = np.vstack([self.fields, new_fields])\n",
    "        self.targets = np.concatenate([self.targets, new_targets])\n",
    "        \n",
    "        self.data = pd.concat([self.data, data])\n",
    "        \n",
    "        \n",
    "        # Dimensions\n",
    "        \n",
    "        self.field_dimensions = np.max(self.fields, axis=0).astype(int) + 1\n",
    "        \n",
    "        self.field_dimensions[self.field_dimensions < 2] = 2\n",
    "        \n",
    "    \n",
    "    def unify_column_names(self, column_names):\n",
    "        \n",
    "        new_column_names = []\n",
    "        \n",
    "        for column_name in column_names:\n",
    "                        \n",
    "            if '_' in column_name:\n",
    "                \n",
    "                column_name_parts = column_name.split('_')\n",
    "                \n",
    "                new_column_name = '_'.join(column_name_parts[1:])\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                new_column_name = column_name\n",
    "                \n",
    "            new_column_names.append(new_column_name)\n",
    "        \n",
    "        column_mapping = dict(zip(column_names, new_column_names))\n",
    "        \n",
    "        return column_mapping\n",
    "    \n",
    "    \n",
    "    def encode(self, symbols):\n",
    "        \n",
    "        # binary = [bit for nucleotide in dna_sequence \n",
    "        #           for bit in self.dna_encoding[nucleotide]]\n",
    "        \n",
    "        bits = []\n",
    "\n",
    "        for symbol in symbols:\n",
    "\n",
    "            bits.extend(self.encoding[symbol])\n",
    "\n",
    "        return bits\n",
    "    \n",
    "    \n",
    "    def decode(self, bits):\n",
    "        \n",
    "        symbols = ''\n",
    "        \n",
    "        # bit_chunks = zip(bits[0::2], bits[1::2])\n",
    "        \n",
    "        bit_chunks = np.array(bits).reshape(-1, self.bits_per_symbol)\n",
    "        \n",
    "        for bit_chunk in bit_chunks:\n",
    "        \n",
    "            symbols += self.decoding.get(tuple(bit_chunk), 'X')\n",
    "            \n",
    "        return symbols\n",
    "        \n",
    "        \n",
    "    def save(self, file_path):\n",
    "        \n",
    "        self.data.to_csv(file_path, index=False)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.fields.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        fields = self.fields[index]\n",
    "        target = self.targets[index].squeeze()\n",
    "        \n",
    "        return fields, target\n",
    "    \n",
    "    \n",
    "    def append_records(self, new_fields, new_targets, record_repetitions_count):\n",
    "        \n",
    "        new_rows_count = new_fields.shape[0] * record_repetitions_count\n",
    "    \n",
    "        new_fields_array = np.tile(new_fields, (record_repetitions_count, 1))\n",
    "        new_targets_array = np.tile(new_targets, (record_repetitions_count, 1)).ravel()\n",
    "\n",
    "        self.fields = np.vstack((self.fields, new_fields_array))\n",
    "        self.targets = np.concatenate((self.targets, new_targets_array))\n",
    "        \n",
    "        # TODO: append to self.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
