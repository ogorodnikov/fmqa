{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8101d794-a97c-476f-b609-767c28e7181d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1) One Hot Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba46bd1-4516-4f6a-9af4-60f68b6918f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesEmbedding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, field_dimensions, embedding_dimensions):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        fields_count = sum(field_dimensions)\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(fields_count, embedding_dimensions)\n",
    "        \n",
    "        field_offsets = np.cumsum(field_dimensions)\n",
    "        \n",
    "        self.embedding_offsets = np.array((0, *field_offsets[:-1]), dtype=int)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "        \n",
    "        # print(\"fields_count:\", fields_count)\n",
    "        # print(\"field_offsets:\", field_offsets)        \n",
    "        # print(\"self.embedding_offsets:\", self.embedding_offsets)\n",
    "        # print(\"self.embedding.weight.data:\", self.embedding.weight.data)\n",
    "        \n",
    "        \n",
    "    def forward(self, embedding_inputs):\n",
    "        \n",
    "        one_hot_offsets = embedding_inputs.new_tensor(self.embedding_offsets).unsqueeze(0)\n",
    "\n",
    "        one_hot_positions = embedding_inputs + one_hot_offsets\n",
    "        \n",
    "        embedding_weights = self.embedding(one_hot_positions)\n",
    "        \n",
    "        # print(\"embedding_inputs:\", embedding_inputs)        \n",
    "        # print(\"one_hot_positions:\", one_hot_positions)        \n",
    "        # print(\"embedding_weights:\", embedding_weights)\n",
    "        \n",
    "        return embedding_weights\n",
    "    \n",
    "    \n",
    "class FeaturesLinear(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, field_dims, output_dim=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=int)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        \n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias\n",
    "    \n",
    "\n",
    "class OneHotFactorizationMachine(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, field_dimensions, embedding_dimensions, include_linear=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = FeaturesEmbedding(field_dimensions, embedding_dimensions)\n",
    "        \n",
    "        self.include_linear = include_linear\n",
    "        \n",
    "        if self.include_linear:\n",
    "            \n",
    "            self.linear = FeaturesLinear(field_dimensions)\n",
    "        \n",
    "    \n",
    "    def predict(self, weights):\n",
    "\n",
    "        square_of_sum = torch.sum(weights, dim=1) ** 2\n",
    "        sum_of_squares = torch.sum(weights ** 2, dim=1)\n",
    "        \n",
    "        predictions = square_of_sum - sum_of_squares           \n",
    "        \n",
    "        predictions = torch.sum(predictions, dim=1, keepdim=True)\n",
    "        \n",
    "        predictions = 0.5 * predictions\n",
    "\n",
    "        # print(\"square_of_sum:\", square_of_sum)    \n",
    "        # print(\"sum_of_squares:\", sum_of_squares)               \n",
    "        # print(\"prediction:\", prediction)        \n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    def forward(self, fields):  \n",
    "        \n",
    "        weights = self.embedding(fields)\n",
    "        \n",
    "        predictions = self.predict(weights).squeeze(1)\n",
    "        \n",
    "        \n",
    "        if self.include_linear:\n",
    "        \n",
    "            linear_predictions = self.linear(fields).squeeze(1)\n",
    "            \n",
    "            predictions += linear_predictions\n",
    "        \n",
    "        # print(\"fields:\", fields)    \n",
    "        # print(\"weights:\", weights)               \n",
    "        # print(\"predictions:\", predictions.shape, predictions)  \n",
    "        \n",
    "        return predictions    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209c778-8629-4a3f-a26d-0114d047999d",
   "metadata": {},
   "source": [
    "### 2) One Cold Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514f9e0-eeba-4cb2-90ec-446ece09dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneColdFactorizationMachine(torch.nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, field_dimensions, embedding_dimensions, include_linear=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        fields_length = len(field_dimensions)\n",
    "        \n",
    "        \n",
    "        initial_weights = torch.zeros((fields_length, embedding_dimensions))\n",
    "                              \n",
    "        self.weights = torch.nn.Parameter(initial_weights)\n",
    "                                      \n",
    "        torch.nn.init.xavier_uniform_(self.weights.data)\n",
    "        \n",
    "        \n",
    "        self.include_linear = include_linear\n",
    "        \n",
    "        if self.include_linear:\n",
    "        \n",
    "            self.linear = torch.nn.Linear(fields_length, 1)\n",
    "            \n",
    "        # print(\"self.weights:\", self.weights.shape, self.weights)\n",
    "\n",
    "                                      \n",
    "    def forward(self, fields):\n",
    "               \n",
    "        masked_weights = fields.unsqueeze(2) * self.weights\n",
    "        \n",
    "        square_of_sum = masked_weights.sum(dim=1) ** 2\n",
    "        \n",
    "        sum_of_squares = (masked_weights ** 2).sum(dim=1)\n",
    "        \n",
    "        predictions = 0.5 * (square_of_sum - sum_of_squares).sum(dim=1)\n",
    "        \n",
    "        \n",
    "        if self.include_linear:\n",
    "        \n",
    "            linear_out = self.linear(fields.float()).squeeze()\n",
    "\n",
    "            predictions += linear_out\n",
    "\n",
    "        # print(\"inputs:\", inputs.shape, inputs)     \n",
    "        # print(\"self.weights:\", self.weights.shape, self.weights) \n",
    "        # print(\"masked_weights:\", masked_weights.shape, masked_weights)\n",
    "        # print(\"square_of_sum:\", square_of_sum.shape, square_of_sum)\n",
    "        # print(\"sum_of_squares:\", sum_of_squares.shape, sum_of_squares)           \n",
    "        # print(\"predictions:\", predictions.shape, predictions)\n",
    "        \n",
    "        return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
